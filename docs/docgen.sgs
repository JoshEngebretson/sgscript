
global WEB;
if( !isset( _G, "WEB" ) )
	WEB = false;

if( !WEB )
	println( "--- SGScript documentation generator ---" );

include "string", "fmt", "io", "re", "../bin/sgsjson";
include "markdown";


function generate_alias( name )
{
	if( string_find( name, "//" ) !== null )
		return name;
	name = re_replace( name, "#[^a-zA-Z0-9]+#", "-" );
	name = string_trim( name, "-" );
//	name = string_tolower( name );
	return name;
}

function full_alias( name, type )
{
	if( type != "info" )
		name $= " " $ type;
	return generate_alias( name );
}


///////////////////////
// LOADING & PARSING //
///////////////////////

function load_docfile( name )
{
	println( "parsing documentation file '" $ name $ "'..." );

	raw = io_file_read( name $ ".txt" );

	/*
		EXTRACT TAGS
	*/
	lines = string_explode( string_replace( raw, ["\r\n","\r"], "\n" ), "\n" );
	doc_title = lines.shift();
	tags = [];
	foreach( id, line : lines )
	{
		if( line.length < 1 || line[0] != "#" )
		{
			if( tags.size && isset( tags.last, "lines" ) )
			{
				if( string_find( line, "~!~" ) === 0 && string_find( line, "=" ) !== false )
				{
					paramdata = string_explode( string_part( line, 3 ), "=" );
					key = string_trim( paramdata.shift() );
					value = string_trim( string_implode( paramdata, "=" ) );
					tags.last[ key ] = value;
				}
				else
					tags.last.lines.push( line );
			}
			
			continue;
		}
		
		if( string_find( line, ">>>" ) !== null )
		{
			alias = string_trim( string_cut( line, 2, string_find( line, ">>>" ) - 1 ) );
			tags.push({ id = id, type = ">", alias = alias });
		}
		else if( string_find( line, "<<<" ) !== null )
		{
			tags.push({ id = id, type = "<" });
		}
		else
		{
			pos2 = string_find_rev( line, "]" );
			if( pos2 !== null )
			{
				pos1 = string_find_rev( line, "[" );
				if( pos1 !== null && pos1 < pos2 )
				{
					page_name = string_trim( string_cut( line, 2, pos1 - 1 ) );
					page_type = string_trim( string_part( line, pos1 + 1, pos2 - pos1 - 1 ) );
					tags.push
					({
						id = id,
						type = "+",
						pagename = page_name,
						pagetype = page_type,
						lines = []
					});
				}
			}
		}
	}
	
	return doc_title, tags;
}


///////////////////////
//   RENDERING       //
///////////////////////

function render_pages( tags )
{
	/*
		GENERATE PAGES
	*/
	
	pgstack = [];
	lastpage = null;
	parts = [];
	to_render = [];
	foreach( tag_id, tag : tags )
	{
		if( tag.type == "+" )
		{
			alias = full_alias( tag.pagename, tag.pagetype );
			path = clone( pgstack ).push( alias );
			ipath = string_implode( path, "/" );
			path_str = alias; // string_implode( path, "/" );
			title = tag.pagename;
			if( tag.pagetype != "info" && tag.pagetype != "toc" )
				title $= " [" $ tag.pagetype $ "]";
			lastpage = alias;
			part =
			{
				path = path,
				ipath = ipath,
				path_str = path_str,
				pagename = tag.pagename,
				pagetype = tag.pagetype,
				title = title,
				body = null
			};
			if( isset( tag, "render" ) )
			{
				to_render.push({ mode = tag.render, filter_type = tag.filter_type, part = part });
			}
			else
			{
				part.body = string_implode( tag.lines, "\n" );
			}
			parts.push( part );
		}
		else if( tag.type == ">" )
		{
			pgstack.push( lastpage );
		}
		else if( tag.type == "<" )
		{
			pgstack.pop();
		}
	}
	
	foreach( render_item : to_render )
	{
		if( render_item.mode == "list_pages_asc" )
		{
			part = render_item.part;
			types = string_explode( render_item.filter_type, "," );
			array_process( types, function( v ){ return string_trim( v ); } );
			
			basepath = clone( part.path );
			basepath[ basepath.size - 1 ] = "";
			basepath = string_implode( basepath, "/" );
			
			items = [];
			foreach( P : parts )
			{
				if( string_find( P.ipath, basepath ) === 0 && types.find( P.pagetype ) !== null )
				{
					items.push( "- @\"" $ P.title $ "\"" );
				}
			}
			items.sort();
			
			part.body = string_implode( items, "\n" );
		}
	}
	
	return parts;
}


///////////////////////
//   COMPOSITION     //
///////////////////////

function find_closest_pathstr( link, pages )
{
	matches = [];
	foreach( P : pages )
	{
		if( string_find( P.path_str, link ) === 0 )
			matches.push( P.path_str );
	}
	if( matches )
	{
		matches.sort_custom( function( a, b ){ return a.length - b.length; } );
		return matches[ 0 ];
	}
	println( "warning: match for link '" $ link $ "' was not found!" );
	return link;
}

function linkhandler_htm( title, link, pages )
{
	link ||= title;
	link = generate_alias( link );
	if( string_find( link, "//" ) === null )
		link = "#" $ find_closest_pathstr( link, pages );
	return '<a href="' $ htmlencode( link ) $ '">' $ htmlencode( title ) $ '</a>';
}

function output_data_htm( name, doc_title, tags, pages )
{
	data = "<h1>" $ htmlencode( doc_title ) $ "</h1>";
	
	// check if TOC already exists
	has_toc = false;
	foreach( P : pages )
	{
		if( P.pagetype == "toc" )
		{
			has_toc = true;
			break;
		}
	}
	
	// add TOC if there's none
	if( !has_toc )
	{
		data $= "<div><h2>Table of Contents</h2>";
		ulevel = 0;
		foreach( P : pages )
		{
			if( !P.path_str || P.pagetype != "info" )
				continue;
			newulev = P.path.size;
			data $= uladjust( ulevel, newulev );
			data $= "<a href='#" $ P.path_str $ "'>" $ htmlencode( P.title ) $ "</a>\r\n";
			ulevel = newulev;
		}
		data $= uladjust( ulevel, 0 );
		data $= "</div>";
	}
	
	mdlh = function( title, link ) use( pages ){ return linkhandler_htm( title, link, pages ); };
	
	data $= "<div>";
	foreach( P : pages )
	{
		if( !P.path_str )
			continue;
		
		data $= "\n<div class='item'>";
		data $= "<a name='" $ P.path_str $ "'></a>";
		data $= "<hr><h2>";
		data $= htmlencode( P.title );
		data $= "</h2>";
		
		data $= markdown2html( P.body, mdlh );
		
		data $= "</div>";
	}
	data $= "\n</div>";
	
	fullfile = '<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" '$
		'"http://www.w3.org/TR/html4/loose.dtd">
	<html><head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>' $ htmlencode( doc_title ) $ '</title>
		<link rel="stylesheet" type="text/css" href="docs.css">
		<script type="text/javascript" src="docs.js"></script>
	</head><body>
	'  $ data $ '
	</body></html>
	';
	
	io_file_write( name $ ".htm", fullfile );
}

function linkhandler_web( title, link, pages )
{
	link ||= title;
	link = generate_alias( link );
	if( string_find( link, "//" ) === null )
		link = find_closest_pathstr( link, pages );
	return '<a href="' $ htmlencode( link ) $ '">' $ htmlencode( title ) $ '</a>';
}


/// SEARCH DATA
function html_to_text( text )
{
	text = re_replace( text, "#<[^>]+>#", "" );
	text = string_translate( text, {
		"&quot;" = "\"",
		"&#39;" = "\'",
		"&lt;" = "<",
		"&gt;" = ">",
		"&amp;" = "&",
	});
	return text;
}

global unnecessary_words = string_explode(
	"and,or,if,else,for,but,when,is,not,however,it,this,to,the,in,thus,be,that,of,"$
	"get,set,does,doesn,t,a,all,none,some,many,with,its,can,also,the,there,are,do,"$
	"while,yes,no,maybe,any,than,then,pre,post,isn",
	"," );
function necessary_word( word )
{
	if( word.length <= 3 )
		return null;
	return unnecessary_words.find( word ) === null;
}

function normalize_word( word )
{
	if( string_find( word, "_" ) !== null )
		return word;
	return re_replace( word, "#(tion|ing|er|ed|es|y|e|s|t)$#", "" );
}

function split_into_normalized_words( text )
{
	text = re_replace( text, "#[^a-zA-Z0-9_]+#", " " );
	words = string_explode( text, " " );
	out = [].reserve( words.size );
	foreach( word : words )
	{
		word = string_tolower( word );
		if( word && necessary_word( word ) )
		{
			word = normalize_word( word );
			if( necessary_word( word ) )
				out.push( word );
		}
	}
	return out;
}

function set_insert( set, item )
{
	if( isset( set, item ) )
		return set[ item ];
	else
	{
		id = dict_size( set );
		set[ item ] = id;
		return id;
	}
}

function mapset_insert( mapset, key, value )
{
	if( !isset( mapset, key ) )
		mapset[ key ] = {};
	return set_insert( mapset[ key ], value );
}

global Indexer = {};
function Indexer.create()
{
	data =
	{
		words = {},
		pages = {},
		firsttwo = {},
	};
	return class( data, Indexer );
}
function Indexer.addPage( page_url )
{
	page_id = dict_size( this.pages );
	this.pages[ page_url ] = page_id;
	return page_id;
}
function Indexer.index( page_id, text, factor )
{
	factor = toreal( factor );
	if( !factor )
		return WARNING( "invalid factor specified" );
	wordlist = split_into_normalized_words( text );
	
	foreach( word : wordlist )
	{
		wordinfo = @this.words[ word ];
		
		if( !wordinfo )
		{
			word_id = dict_size( this.words );
			this.words[ word ] = wordinfo = [ word_id, word, {} ];
		}
		else
			word_id = wordinfo[0];
		
		wordpages = wordinfo[2];
		if( !isset( wordpages, page_id ) )
			wordpages[ page_id ] = factor;
		else
			wordpages[ page_id ] += factor;
		
		ftw = string_part( word, 0, 2 );
		mapset_insert( this.firsttwo, ftw, word_id );
	}
}
function Indexer.getData()
{
	out_words = [];
	out_pages = [];
	out_firsttwo = {};
	
	foreach( word : this.words )
		out_words.push([ word[1], word[2] ]);
	
	foreach( page ,: this.pages )
		out_pages.push( page );
	
	foreach( key, item : this.firsttwo )
	{
		widlist = [];
		foreach( wid ,: item )
			widlist.push( toint( wid ) );
		out_firsttwo[ key ] = widlist;
	}
	
	return
	{
		words = out_words,
		pages = out_pages,
		firsttwo = out_firsttwo,
	};
}

function generate_search_data_web( pages )
{
	/*
		Expected search process:
		INPUT: word-list
		OUTPUT: page-list, sorted
		DATA:
		- words - array( word[ word_text, pages = array( pageref[ page_id, factor ] ) ] )
		- pages - array( page[ page_url ] )
		- firsttwo - map( {string,2} => array( word_id ) )
		ALGORITHM:
		- gather possible-word-id-list from word-list via 'firsttwo'
		- gather word-id-list from possible-word-id-list by filtering via 'words.word_text'
		- gather page-id-list from word-id-list via 'words.pages', add factors
		- sort page-id-list by factor
	*/
	
	indexer = Indexer.create();
	
	foreach( P : pages )
	{
		page_id = indexer.addPage( P.path_str );
		
		pp_title = string_trim( re_replace( P.title, "#^(.*)\\[.*?\\]$#", "$1" ) );
		pp_text = html_to_text( P.body );
		
		indexer.index( page_id, pp_title, 1.3 );
		indexer.index( page_id, pp_text, 1.0 );
	}
	
	return indexer.getData();
}
///


function output_data_web( name, doc_title, tags, pages )
{
	mdlh = function( title, link ) use( pages ){ return linkhandler_web( title, link, pages ); };
	
	toclist = [];
	data = "";
	foreach( P : pages )
	{
		if( !P.path_str )
			continue;
		
		tocitem_from = data.length;
		data $= markdown2html( P.body, mdlh );
		tocitem_to = data.length;
		
		toclist.push([ tocitem_from, tocitem_to, string_implode( P.path, "/" ), P.title ]);
	}
	
	searchdata = generate_search_data_web( pages );
	
	io_file_write( "out/" $ name $ ".htm", data );
	io_file_write( "out/" $ name $ ".toc", json_encode( toclist ) );
	io_file_write( "out/" $ name $ ".sda", json_encode( searchdata ) );
}

function generate_docdata( name )
{
	(doc_title,tags) = load_docfile( name );
	pages = render_pages( tags );
	
	if( WEB )
		output_data_web( name, doc_title, tags, pages );
	else
		output_data_htm( name, doc_title, tags, pages );
}


file = @argv[1];
if( file )
	generate_docdata( file );
else
{
	generate_docdata( "sgscript.docs" );
	generate_docdata( "sgs.cppbc.docs" );
	generate_docdata( "sgs.sockets.docs" );
	generate_docdata( "sgs.xgmath.docs" );
	generate_docdata( "sgs.json.docs" );
	generate_docdata( "sgs.meta.docs" );
	generate_docdata( "sgscript.tutorial" );
}


println( "done!" );
